name: Acceptance Test cases
on:
  pull_request:
  workflow_dispatch:
    inputs:
      branch:
        description: "Branch to run against"
        required: true
        default: "master"
  repository_dispatch:
    types: [ok-to-test-command]
  
jobs:
  setup:
    name: ðŸŒ± Environment Setup
    runs-on: self-hosted
    steps:
      - name: Trigger Event
        run: |
          echo "ðŸŽ‰ The job was automatically triggered by a ${{ github.event_name }} event."

      - name: Runner Info
        run: |
          echo "ðŸ§ This job is now running on runner: $RUNNER_NAME (OS: ${{ runner.os }})"

      - name: Pull Request Info
        run: |
          echo "your repository is ${{ github.repository }}."
          echo "PR Number: ${{ github.event.client_payload.pull_request.number }}"
          echo "Branch Name: ${{ github.event.client_payload.pull_request.head.ref }}"

      - name: Check out repository code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch }}

      - name: Remove Cached Go Versions
        run: |
          sudo rm -rf /home/ubuntu/actions-runner/_work/_tool/go
          sudo rm -rf /usr/local/go
          sudo apt remove --purge golang -y
          hash -r  # Clear shell path cache

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.20'
          check-latest: true  # Ensures the latest patch of Go 1.20 is installed
          cache: true  # Enables module caching

      - name: Verify Go Installation
        run: |
          go version
          which go

      - name: Set Go Environment
        run: |
          echo "GOPATH=$HOME/go" >> $GITHUB_ENV
          echo "PATH=$HOME/go/bin:$PATH" >> $GITHUB_ENV

      - name: Cache Go Modules
        uses: actions/cache@v3
        with:
          path: |
            ~/go/pkg/mod
          key: go-mod-${{ runner.os }}-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            go-mod-${{ runner.os }}-

      - name: Install Dependencies
        run: |
          go mod tidy
          go mod vendor

      - name: Install unzip and sshpass
        run: |
          sudo apt-get update && sudo apt-get install -y unzip sshpass

      - name: Setup Terraform v1.10.5
        run: |
          set -e  # Exit on error
          TERRAFORM_VERSION="1.10.5"
          curl -fsSL -o terraform.zip "https://releases.hashicorp.com/terraform/${TERRAFORM_VERSION}/terraform_${TERRAFORM_VERSION}_linux_amd64.zip"
          
          if [ ! -f terraform.zip ]; then
            echo "Terraform zip file not found!"
            exit 1
          fi
          unzip terraform.zip
          sudo mv terraform /usr/local/bin/
          rm terraform.zip  # Cleanup
          echo "âœ… Terraform Installed Successfully!"
          terraform version

      - name: Set environment variables
        run: |
            echo "NUTANIX_PE_PASSWORD=${{ secrets.NUTANIX_PE_PASSWORD }}" >> $GITHUB_ENV
            echo "NUTANIX_PE_USERNAME=${{ secrets.NUTANIX_PE_USERNAME }}" >> $GITHUB_ENV
            echo "NUTANIX_USERNAME=${{ secrets.NUTANIX_USERNAME }}" >> $GITHUB_ENV
            echo "NUTANIX_PASSWORD=${{ secrets.NUTANIX_PASSWORD }}" >> $GITHUB_ENV
            echo "NUTANIX_INSECURE=${{ secrets.NUTANIX_INSECURE }}" >> $GITHUB_ENV
            echo "NUTANIX_PORT=${{ secrets.NUTANIX_PORT }}" >> $GITHUB_ENV
            echo "NUTANIX_ENDPOINT=${{ secrets.NUTANIX_ENDPOINT }}" >> $GITHUB_ENV
            echo "NUTANIX_STORAGE_CONTAINER=${{ secrets.NUTANIX_STORAGE_CONTAINER }}" >> $GITHUB_ENV
            echo "FOUNDATION_ENDPOINT=${{ secrets.FOUNDATION_ENDPOINT }}" >> $GITHUB_ENV
            echo "FOUNDATION_PORT=${{ secrets.FOUNDATION_PORT }}" >> $GITHUB_ENV
            echo "NOS_IMAGE_TEST_URL=${{ secrets.NOS_IMAGE_TEST_URL }}" >> $GITHUB_ENV
            echo "NDB_ENDPOINT=${{ secrets.NDB_ENDPOINT }}" >> $GITHUB_ENV
            echo "NDB_PASSWORD=${{ secrets.NDB_PASSWORD }}" >> $GITHUB_ENV
            echo "NDB_USERNAME=${{ secrets.NDB_USERNAME }}" >> $GITHUB_ENV
            echo "PROTECTION_RULES_TEST_FLAG=${{ secrets.PROTECTION_RULES_TEST_FLAG }}" >> $GITHUB_ENV
            echo "CGO_ENABLED=${{ secrets.CGO_ENABLED }}" >> $GITHUB_ENV

      - name: Check gofmt
        run: |
            echo "==> Checking that code complies with gofmt requirements..."
            gofmt_files=$(gofmt -l `find . -name '*.go' | grep -v vendor`)
            if [[ -n ${gofmt_files} ]]; then
                echo 'gofmt needs running on the following files:'
                echo "${gofmt_files}"
                echo "You can use the command: \`make fmt\` to reformat code."
                exit 1
            else
                echo "No gofmt issues found."
            fi
        continue-on-error: true

  tests:
    name: ðŸƒðŸ› ï¸ Tests Execution
    runs-on: self-hosted
    needs: setup
    steps:
      - name: Acceptance test cases
        run: |
              args="${{ github.event.client_payload.slash_command.args }}"
              providers=(${args})
              index=0
              n=${#providers[@]}
              runFlag=""
              for provider in $args
              do 
                  if [ "$provider" = "foundation" ]
                      then 
                          runFlag+="TestAccFoundation*"
                  elif [ "$provider" = "foundation_central" ]
                      then
                          runFlag+="TestAccFC*"
                  elif [ "$provider" = "karbon" ]
                      then
                          runFlag+="TestAccKarbon*"
                  elif [ "$provider" = "v3" ]
                      then
                          runFlag+="TestAccNutanix*"
                  elif [ "$provider" = "v4" ]
                      then
                          runFlag+="TestAccV2Nutanix*"
                  elif [ "$provider" = "lcm" ]
                      then
                          runFlag+="TestAccV2NutanixLcm*"
                  elif [ "$provider" = "era" ]
                      then
                          runFlag+="TestAccEra*"
                  else
                      echo "running individual testcase/package"
                      runFlag+="$provider"
                  fi
                  if [ $index -lt $((n-1)) ]
                      then
                          runFlag+="|"
                  fi
                  index=$((index+1))
              done
              export TESTARGS="-run=TestAccV2NutanixLcmEntitiesDatasource_InvalidFilter"
              echo "TESTARGS = $TESTARGS"
              echo "==> Setup Foundation Config"
              echo '${{ secrets.FOUNDATION_CONFIG }}' > test_foundation_config.json
              echo "==> Setup PC Config"
              echo '${{ secrets.PC_CONFIG }}' > test_config.json
              echo "==> Setup V4 Config"
              echo '${{ secrets.V4_CONFIG }}' > test_config_v2.json
              echo "==> Running testcases..."
              TF_LOG="ERROR" TF_ACC=1  GOTRACEBACK=all go test ./... -v ${TESTARGS} -timeout 500m -coverprofile c.out -covermode=count | tee test_output.log
              
              set +e  # Ignore failures

              # Ensure log file exists
              if [ ! -f test_output.log ]; then
                  echo "Error: test_output.log not found!"
                  exit 0  # Ignore missing file instead of failing
              fi

              # Extract total test cases executed safely
              TOTAL_RUN=$(grep -c '^=== RUN' test_output.log || echo 0)
              TOTAL_PASSED=$(grep -c '^--- PASS' test_output.log || echo 0)
              TOTAL_FAILED=$(grep -c '^--- FAIL' test_output.log || echo 0)
              TOTAL_SKIPPED=$(grep -c '^--- SKIP' test_output.log || echo 0)

              # Calculate percentages safely
              if [ "$TOTAL_RUN" -gt 0 ]; then
                  PASS_PERCENT=$((TOTAL_PASSED * 100 / TOTAL_RUN))
                  FAIL_PERCENT=$((TOTAL_FAILED * 100 / TOTAL_RUN))
                  SKIP_PERCENT=$((TOTAL_SKIPPED * 100 / TOTAL_RUN))
              else
                  PASS_PERCENT=0
                  FAIL_PERCENT=0
                  SKIP_PERCENT=0
              fi

              echo "==================================================ðŸ§ª TEST SUMMARY ðŸ§ª================================================================================="
              echo "Total Test Cases Run ðŸ¹ðŸš€: $TOTAL_RUN"
              echo "Total Test Cases Passed ðŸ¹âœ…: $TOTAL_PASSED ($PASS_PERCENT %)" 
              echo "Total Test Cases Failed ðŸ¹âŒ: $TOTAL_FAILED ($FAIL_PERCENT %)"
              echo "Total Test Cases Skipped ðŸ¹âš ï¸: $TOTAL_SKIPPED ($SKIP_PERCENT %)"
              echo "=================================================================================================================================================="

              echo "================================================== TESTS SUCCEEDED âœ… ============================================================================="
              if [ "$TOTAL_PASSED" -gt 0 ]; then
                  echo ""
                  grep '^--- PASS' test_output.log | awk '{print "âœ… " $3}' || true
              fi

              echo "==================================================================================================================================================="
              echo "================================================== TESTS FAILED âŒ ================================================================================"
              if [ "$TOTAL_FAILED" -gt 0 ]; then
                  echo ""
                  grep '^--- FAIL' test_output.log | awk '{print "âŒ " $3}' || true
              fi

              echo "==================================================================================================================================================="
              echo "================================================== TESTS SKIPPED âš ï¸ =============================================================================="
              if [ "$TOTAL_SKIPPED" -gt 0 ]; then
                  awk '
                    /^=== RUN/ { testname=$3; reason="No reason provided" }
                    /--- SKIP/ { print "âš ï¸ " testname "   : Reason: âž¡ï¸ :  " reason }
                    /^[[:space:]]+/ { reason=$0 }' test_output.log || true
              fi

              echo "==================================================================================================================================================="
              if [ "$TOTAL_FAILED" -gt 0 ]; then
                  echo ""
                  echo "================== FAILURE DETAILS OF TESTCASES EXECUTED ==============================================================================================="
                  grep '^=== RUN' test_output.log | awk '{print $3}' | while read -r test; do
                      if grep -q "^--- FAIL: $test" test_output.log; then
                          echo "TESTCASE: $test"
                          echo "========================================ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ðŸ“ TRACEBACK ðŸ“ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥ ======================================================================================="
                          awk "/=== RUN   $test/,/--- FAIL: $test/" test_output.log | sed 's/^/    /' || true
                          echo "==========================================================================================================================================================="
                      fi
                  done
              fi

              echo "Tests Execution is done, please debug if any failures"

              # ðŸ” This now ensures the stage fails if tests fail
              if [ "$TOTAL_FAILED" -gt 0 ]; then
                  exit 1
              else
                  exit 0
              fi

  coverage:
    name: ðŸ“Š Code Coverage Check
    needs: tests
    runs-on: self-hosted
    steps:
      -name: Code Coverage
      if: ${{ always() }}
      run:  |
            echo "Code coverage: Checking if code coverage is above threshold..."
            export TESTCOV_THRESHOLD=50
            echo "Threshold: $TESTCOV_THRESHOLD %"
            totalCoverage=`go tool cover -func=c.out | grep total | grep -Eo '[0-9]+\.[0-9]+'`
            echo "Current test coverage : $totalCoverage %"
            if (( $(echo "$totalCoverage $TESTCOV_THRESHOLD" | awk '{print ($1 > $2)}') )); then
                echo "CODE_COVERAGE_OUTPUT=Line code coverage is $totalCoverage" >> $GITHUB_ENV
                echo "Line coverage is $totalCoverage"
            else
                echo "CODE_COVERAGE_OUTPUT=Current line coverage ($totalCoverage) is below threshold ($TESTCOV_THRESHOLD). Kindly add more acceptance tests." >> $GITHUB_ENV
                echo "Current coverage ($totalCoverage) is below threshold ($TESTCOV_THRESHOLD)."
            fi
  
  report:
    name: ðŸ“¢ Report Generation
    needs: coverage
    runs-on: self-hosted
    steps:
      - name: Generate Report
        uses: peter-evans/create-or-update-comment@v4
        if: ${{ always() }}
        with:
          issue-number: 877
          body: |
            ðŸ§ª **Acceptance test run status:** `${{ job.status }}`

            **ðŸ“Œ [View Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})**

            ```txt
            akhil gullapalli
            ```
          reaction-type: hooray
  
  status:
    name: ðŸš¦ Workflow Status
    if: ${{ always() }}
    runs-on: self-hosted
    steps:
    - name: Show job status
      run: |
        STATUS="${{ job.status }}"
        if [ "$STATUS" == "failure" ]; then
          echo "Job Status: $STATUS ðŸ˜¢"
        else
          echo "Job Status: $STATUS âœ…"
        fi
        

      # # Update the comment back
      # - name: Update comment
      #   uses: peter-evans/create-or-update-comment@v1
      #   if: ${{ always() }}
      #   with:
      #     comment-id: ${{ github.event.client_payload.github.payload.comment.id }}
      #     body: |
      #       ```
      #       Acceptance test run status: ${{ job.status }}
      #       **ðŸ“Œ [View GitHub Actions Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})**
      #       ${{ env.CODE_COVERAGE_OUTPUT }}

      #       ```
      #     reaction-type: hooray
      #   continue-on-error: true

      # Print job status